{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from hipe4ml.model_handler import ModelHandler\n",
    "import ROOT\n",
    "ROOT.gSystem.Load('../pdfLib/libRooATan.dylib')\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.append('../include')\n",
    "import utils\n",
    "import para as para\n",
    "import fRead as fRead\n",
    "import simultaneous_fit as emFit\n",
    "import plot as plot\n",
    "from Data import dataInterval, mcDataInterval, dataGroup, mcDataGroup\n",
    "\n",
    "#ROOT.Math.IntegratorOneDimOptions.SetDefaultRelTolerance(1.E-16)\n",
    "ROOT.Math.IntegratorOneDimOptions.SetDefaultIntegrator(\"GaussLegendre\")\n",
    "#“1-dim integrators”: “Gauss”, “GaussLegendre”, “Adaptive”, “AdaptiveSingular” “NonAdaptive”\n",
    "utils.set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Set paramters ##########\n",
    "CENT_BIN_LIST = para.CENT_BIN_LIST\n",
    "# PT_BIN_LIST = para.PT_BIN_LIST\n",
    "PT_BIN_LIST = para.PT_BIN_LIST_PERFORMANCE\n",
    "# PT_BIN_LIST = para.PT_BIN_LIST_NEW\n",
    "# PT_BIN_LIST = para.PT_BIN_LIST_TEST\n",
    "MASS_BIN = para.MASS_BIN\n",
    "MODEL_Eff_LIST = para.MODEL_Eff_LIST\n",
    "\n",
    "sigpdf_list = [\"dscb\"]\n",
    "# bkgpdf_list = [\"argus\", \"Landau\", \"pol5\", \"dscb\"]\n",
    "# bkgpdf_list = [\"argus\", \"pol3\", \"dscb\"]\n",
    "bkgpdf_list = [\"dscb\"]\n",
    "\n",
    "is_single_matter_type = False\n",
    "data_type = \"24skimmed\"\n",
    "# data_type = \"24skimmed_reduced\"\n",
    "# data_type = \"24skimmed_newReduced\"\n",
    "# data_type = \"24newSkimmed\"\n",
    "\n",
    "# bkgType = \"Sideband\"\n",
    "bkgType = \"LikeSign\"\n",
    "\n",
    "pt_dir = utils.convert_ptbin_to_dir(PT_BIN_LIST[0])\n",
    "# ModelPath = \"../MLAna/Model/24skimmed\"\n",
    "# ModelPath = \"../MLAna_LikeSign/Model/24skimmed\"\n",
    "# ModelPath = \"../MLAna_LikeSign_LooseCut/Model/24skimmed\"\n",
    "# ModelPath = f\"../Model/{pt_dir}/24skimmed_{bkgType}\"\n",
    "ModelPath = f\"../ModelLooseCut/{pt_dir}/24skimmed_{bkgType}\"\n",
    "# ModelPath = f\"../Model/{pt_dir}/backup_LikeSign\"\n",
    "\n",
    "if len(sigpdf_list) == 1 and len(bkgpdf_list) == 1:\n",
    "    output_prefix = f'Plot/{pt_dir}/{sigpdf_list[0]}_{bkgpdf_list[0]}/'\n",
    "else:\n",
    "    output_prefix = f\"Plot/{pt_dir}/Merged/\"\n",
    "\n",
    "if not os.path.exists(output_prefix):\n",
    "    os.makedirs(output_prefix)\n",
    "\n",
    "score_eff_arrays_dict = pickle.load(\n",
    "    open(ModelPath + \"/file_score_eff_dict\", \"rb\"))\n",
    "\n",
    "config_file_path = fRead.getConfigPath(data_type)\n",
    "config_file = open(config_file_path, 'r')\n",
    "config = yaml.full_load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Readin dataset and model ############### \n",
    "DataTH = fRead.getDataTH(data_type, period=\"24amanao\")\n",
    "MCTH = fRead.getMCTH(\"24skimmed_newReduced\", period=\"25a3\")\n",
    "BkgTH_mixedDeuteron = fRead.getBkgTH(\"24skimmed_newReduced\", \"mixed_deuteron\", DataTH, period=\"\")\n",
    "BkgTH_mixedUncorrelated = fRead.getBkgTH(\"24skimmed_newReduced\", \"mixed_uncorrelated\", DataTH, period=\"\")\n",
    "\n",
    "DataPDRaw = DataTH.get_data_frame()\n",
    "MCPDRaw = MCTH.get_data_frame()\n",
    "BkgPDRaw_mixed_deuteron = BkgTH_mixedDeuteron.get_data_frame()\n",
    "BkgPDRaw_mixedUncorrelated = BkgTH_mixedUncorrelated.get_data_frame()\n",
    "\n",
    "utils.calNewElements(DataPDRaw)\n",
    "utils.calNewElements(BkgPDRaw_mixed_deuteron)\n",
    "utils.calNewElements(MCPDRaw)\n",
    "utils.calNewElements(BkgPDRaw_mixedUncorrelated)\n",
    "\n",
    "DataTH.set_data_frame(DataPDRaw)\n",
    "BkgTH_mixedDeuteron.set_data_frame(BkgPDRaw_mixed_deuteron)\n",
    "BkgTH_mixedUncorrelated.set_data_frame(BkgPDRaw_mixed_deuteron)\n",
    "MCTH.set_data_frame(MCPDRaw)\n",
    "\n",
    "print(\"Count of Raw Data: \", len(DataPDRaw))\n",
    "print(\"Count of Raw MC: \", len(MCPDRaw))\n",
    "print(\"Count of Raw bkg_mixed_deuteron: \", len(BkgPDRaw_mixed_deuteron))\n",
    "print(\"Count of Raw bkg_mixed_uncorrelated: \", len(BkgPDRaw_mixedUncorrelated))\n",
    "\n",
    "if len(CENT_BIN_LIST) != 1:\n",
    "    raise ValueError(\"CENT_BIN_LIST should have only one element\") # Now we only consider one centrality bin\n",
    "\n",
    "model_hdl = utils.createEmptyList( [len(CENT_BIN_LIST)] )\n",
    "for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "    for pt_bin in PT_BIN_LIST[icent]:\n",
    "        modelfile_name = ModelPath + '/Model' + \"pT\" + str(pt_bin[0]) + \"_\" + str(pt_bin[1])\n",
    "        modelReadin = ModelHandler()\n",
    "        modelReadin.load_model_handler(modelfile_name)\n",
    "        model_hdl[icent].append(deepcopy(modelReadin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Reweight pt shape ###############\n",
    "pt_spectrum = fRead.getHypertritonPtShape(data_type)\n",
    "if PT_BIN_LIST == [[[2,5]]]:\n",
    "    utils.apply_pt_rejection(MCPDRaw, [pt_spectrum], [[-100, 999]], PT_BIN_LIST, option=\"READ\", path=\"dfResults/pTReweight_25a3_pT2_5.pkl\") # centrality unavailable\n",
    "elif PT_BIN_LIST == [[[2, 3], [3, 5]]]:\n",
    "    utils.apply_pt_rejection(MCPDRaw, [pt_spectrum], [[-100, 999]], PT_BIN_LIST, option=\"READ\", path=\"dfResults/pTReweight_25a3_pT2_3_5.pkl\")\n",
    "MCPDRaw = MCPDRaw.query(\"rej == False and fSurvivedEventSelection == True\")\n",
    "# FIXME: The raw pt distribution of mixing background is not flat! Reweight not meaningful\n",
    "# utils.apply_pt_rejection(BkgPDRaw_mixed_deuteron, [pt_spectrum], [[-100, 999]], PT_BIN_LIST, ptcolumn=\"fPt\") # centrality unavailable\n",
    "# BkgPDRaw_mixed_deuteron = BkgPDRaw_mixed_deuteron.query(\"rej == False\")\n",
    "\n",
    "print(\"After pT reweight\")\n",
    "print(\"MC dataset:\",len(MCPDRaw))\n",
    "print(\"Generated MC hypertirton within |y| < 0.5:\", len(MCPDRaw.query(\"fIsSignal == 1 and abs(fGenRapidity) < 0.5\")))\n",
    "print(\"Reconstructed MC hypertirton within 2 <= pT < 5:\", len(MCPDRaw.query(\"fIsSignal == 1 and fPt >= 2 and fPt < 5\")))\n",
    "print(\"Generated MC hypertirton within |y| < 0.5 and 2 <= pT < 3 GeV/c:\", len(MCPDRaw.query(\"fIsSignal == 1 and abs(fGenRapidity) < 0.5 and fGenPt >= 2 and fGenPt < 3\")))\n",
    "print(\"Generated MC hypertirton within |y| < 0.5 and 3 <= pT < 5 GeV/c:\", len(MCPDRaw.query(\"fIsSignal == 1 and abs(fGenRapidity) < 0.5 and fGenPt >= 3 and fGenPt < 5\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Apply precut and add model prediction to data ###############\n",
    "# print(DataPDRaw.columns)\n",
    "\n",
    "# minCosPA = 0.995\n",
    "# maxDCADaughters = 0.1\n",
    "# preCut =   f\"fCt >= 2 and fCt < 40 and \\\n",
    "#             fCosPA > {minCosPA} and \\\n",
    "#             abs(fTPCNSigmaProton) < 3 and abs(fTPCNSigmaBachelor) < 3 and \\\n",
    "#             fDCADaughters < {maxDCADaughters} and \\\n",
    "#             fDCAPionToPV > 0.05\"\n",
    "\n",
    "if \"LooseCut\" in ModelPath:\n",
    "    preCut = utils.convert_sel_to_string(config['MLLoosePreSelection'])\n",
    "else:\n",
    "    preCut = utils.convert_sel_to_string(config['MLPreSelection'])\n",
    "print(\"ML precut:\", preCut)\n",
    "\n",
    "data = dataGroup(DataPDRaw, preCut, CENT_BIN_LIST, PT_BIN_LIST, sigpdf_list, bkgpdf_list, MASS_BIN, data_type, False, model_hdl)\n",
    "data.addModelPrediction()\n",
    "mcdata = mcDataGroup(MCPDRaw, preCut, CENT_BIN_LIST, PT_BIN_LIST, sigpdf_list, bkgpdf_list, MASS_BIN, data_type + \"MC\", False, model_hdl) # cut for pt intervals include fPt > 0\n",
    "mcdata.addModelPrediction()\n",
    "bkg_mixed_deuteron = dataGroup(BkgPDRaw_mixed_deuteron, preCut, CENT_BIN_LIST, PT_BIN_LIST, sigpdf_list, bkgpdf_list, MASS_BIN, data_type + \"Mixed_deuteron\", False, model_hdl)\n",
    "bkg_mixed_deuteron.addModelPrediction()\n",
    "bkg_mixed_uncorrelated = dataGroup(BkgPDRaw_mixedUncorrelated, preCut, CENT_BIN_LIST, PT_BIN_LIST, sigpdf_list, bkgpdf_list, MASS_BIN, data_type + \"Mixed_uncorrelated\", False, model_hdl)\n",
    "bkg_mixed_uncorrelated.addModelPrediction()\n",
    "\n",
    "for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "    for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "        binCutMC = f'(fGenPt >= {pt_bin[0]}) and (fGenPt < {pt_bin[1]})'\n",
    "        print(\"gen\", len(MCPDRaw.query(f\"fIsSignal == 1 and abs(fGenRapidity) < 0.5 and {binCutMC}\")))\n",
    "        print(\"reco:\", len(mcdata.getDF(icent, ipt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Fit MC invariant mass distribution to extract the shape of signal ###############\n",
    "MCFitpara = utils.createEmptyList( [len(CENT_BIN_LIST), len(PT_BIN_LIST[0])] ) # only for DSCB\n",
    "with ROOT.TFile(output_prefix + \"MCfit.root\", \"recreate\") as outfile:\n",
    "    for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "        for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "            (_signalCount, _signalError, paras) = mcdata.invMFit(icent, ipt, \"DSCB\", bkgpdf=\"none\", isMC=True, ifDrawStats=False, outfile = outfile)\n",
    "            MCFitpara[icent][ipt].append(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Fit data ###############\n",
    "outfileName = \"MLsimultaneousfit.root\"\n",
    "with ROOT.TFile(output_prefix + outfileName, \"recreate\") as outfile:\n",
    "    (signalCount, signalError, expBkgCount) = data.doSimultaneousFits(bkg_mixed_deuteron, bkg_mixed_uncorrelated, MODEL_Eff_LIST, score_eff_arrays_dict, \n",
    "                                                                      mcpara_list=MCFitpara, fit_massbin=[2.96, 3.02], outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Absorption factor\n",
    "# AbsorbFactor = fRead.getAbsorpFactor(CENT_BIN_LIST, PT_BIN_LIST, absorp_file = \"../CC_file/absorption_histos_3b.root\")\n",
    "AbsorbFactor = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] # To be implemented\n",
    "\n",
    "############### Calculate efficiency and expected significance ###############\n",
    "with ROOT.TFile(output_prefix + \"MLsimultaneousfit.root\", \"update\") as outfile:\n",
    "    Efficiency, _ExpCorrectSignal = mcdata.calculateEfficiency(MCPDRaw, pt_spectrum, fRead.getEventNumber(data_type), para.BR_3body)\n",
    "    mcdata.saveEfficiencyPlots(outfile)\n",
    "    ExpSignificance = mcdata.getExpSignificance(MODEL_Eff_LIST, expBkgCount)\n",
    "\n",
    "data.setPreCutEfficiency(Efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### QA for BDT model ###############\n",
    "with ROOT.TFile(output_prefix + \"MLsimultaneousfit.root\", \"update\") as outfile:\n",
    "    for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "        outdir_cent = outfile.Get(\"Cent\"+str(cent_bin[0]) + \"_\" + str(cent_bin[1]))\n",
    "        for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "            outdir_pt = outdir_cent.Get(\"pT\"+str(pt_bin[0]) + \"_\" + str(pt_bin[1]))\n",
    "            binkey = \"pT\" + str(pt_bin[0]) + \"_\" + str(pt_bin[1])\n",
    "            modelOutput_x = score_eff_arrays_dict[binkey][0][0:len(MODEL_Eff_LIST)]\n",
    "            BDTefficiency_y = score_eff_arrays_dict[binkey][1][0:len(MODEL_Eff_LIST)]\n",
    "            plot.plot_bdtefficiency_vs_model_output(outdir_pt, modelOutput_x, BDTefficiency_y, pt_bin)\n",
    "\n",
    "            if len(MODEL_Eff_LIST) > len(BDTefficiency_y):\n",
    "                BDTefficiency_y = np.append(BDTefficiency_y, 1)\n",
    "\n",
    "            for isig, sigfunc in enumerate(sigpdf_list):\n",
    "                for ibkg, bkgfunc in enumerate(bkgpdf_list):\n",
    "                    binInfo = f\"pT{pt_bin[0]}-{pt_bin[1]} GeV/c {sigfunc} {bkgfunc}\"\n",
    "                    significance = np.array(ExpSignificance[icent][ipt][isig][ibkg])\n",
    "                    significance_times_BDTEff = significance * BDTefficiency_y\n",
    "                    plot.plot_significance_times_bdtefficiency(outdir_pt, modelOutput_x, significance_times_BDTEff, f\"{binkey}_{sigfunc}_{bkgfunc}\", binInfo)\n",
    "\n",
    "data.setBestBDT(ExpSignificance, BDTefficiency_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### QA and systematical uncertainties ###############\n",
    "SystUnc = utils.createEmptyList( [len(CENT_BIN_LIST)])\n",
    "with ROOT.TFile(output_prefix + \"MLsimultaneousfit.root\", \"update\") as outfile:\n",
    "    for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "        outdir_cent = outfile.Get(\"Cent\"+str(cent_bin[0]) + \"_\" + str(cent_bin[1]))\n",
    "        for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "            outdir_pt = outdir_cent.Get(\"pT\"+str(pt_bin[0]) + \"_\" + str(pt_bin[1]))\n",
    "            CorrectedSignal = [] #list of corrected signal to calculate systematic uncertainties\n",
    "            for isig, sigfunc in enumerate(sigpdf_list):\n",
    "                for ibkg, bkgfunc in enumerate(bkgpdf_list):\n",
    "                    binkey = f\"pT{pt_bin[0]}_{pt_bin[1]}_{sigfunc}_{bkgfunc}\" \n",
    "                    binInfo = f\"pT{pt_bin[0]}-{pt_bin[1]} GeV/c {sigfunc} {bkgfunc}\"\n",
    "                    \n",
    "                    # Use the BDT threshold with the highest (significance * BDT efficiency) as the central value\n",
    "                    best_index = data.getBestBDTIndex(icent, ipt, isig, ibkg)\n",
    "                    SigToBDTefficiency_y = np.array(data.signalCount[icent][ipt][isig][ibkg])/data.bdt_efficiency\n",
    "                    SigToBDTefficiency_errory = np.array(data.signalError[icent][ipt][isig][ibkg])/data.bdt_efficiency\n",
    "\n",
    "                    plot.plot_signal_to_bdtefficiency(outdir_pt, MODEL_Eff_LIST, SigToBDTefficiency_y , SigToBDTefficiency_errory, best_index, binkey, binInfo)\n",
    "                    \n",
    "                    # Vary BDT efficiency to calculate systematic uncertainties\n",
    "                    for var in range(-10, 11):\n",
    "                        if (best_index + var >= len(MODEL_Eff_LIST)) or (best_index + var < 0):\n",
    "                            continue\n",
    "                        CorrectedSignal.append( SigToBDTefficiency_y[best_index+var]/(data.getPrecutEfficiency[icent][ipt] * AbsorbFactor[icent][ipt]) )\n",
    "                        \n",
    "            # Calculate systematic uncertainties\n",
    "            binInfo = f\"pT{pt_bin[0]}-{pt_bin[1]} GeV/c \"\n",
    "            \n",
    "            CorrectedYield_y = np.array(CorrectedSignal)/(fRead.getEventNumber(data_type) * para.BR_3body * (pt_bin[1] - pt_bin[0]))\n",
    "            if not is_single_matter_type:\n",
    "                CorrectedYield_y = CorrectedYield_y * 2\n",
    "            h_CorrectedYield = ROOT.TH1F(\"hCorrectedYield\" + binkey, binInfo + \";Corrected Hypertriton yield;Counts\", 20, 0.8*np.min(CorrectedYield_y), 1.2*np.max(CorrectedYield_y) )\n",
    "            for sigVar in CorrectedYield_y:\n",
    "                h_CorrectedYield.Fill(sigVar)\n",
    "            outdir_pt.WriteObject(h_CorrectedYield, \"hCorrectedYield\" + binkey)\n",
    "            \n",
    "            # New tree to store the corrected yield with 3 sigma region to central value\n",
    "            mean = h_CorrectedYield.GetMean()\n",
    "            rms  = h_CorrectedYield.GetRMS()\n",
    "            xTTree = np.zeros(1, dtype=np.float64)\n",
    "            h_CorrectedYieldTree = ROOT.TH1F(\"hCorrectedYieldTree\" + binkey, binInfo + \";Corrected Hypertriton yield;Counts\", 20, 0.8*np.min(CorrectedYield_y), 1.2*np.max(CorrectedYield_y) )\n",
    "            CorrectedYieldTree = ROOT.TTree(\"CorrectedYield\"+binkey, \"CorrectedYield Tree\")\n",
    "            CorrectedYieldTree.Branch(\"CorrectedYield\",xTTree,'CorrectedYield/D')\n",
    "            for sigVar in CorrectedYield_y:\n",
    "                if abs(sigVar - mean) <= 3 * rms:\n",
    "                    xTTree[0] = sigVar\n",
    "                    h_CorrectedYieldTree.Fill(sigVar)\n",
    "                    CorrectedYieldTree.Fill()\n",
    "            outdir_pt.WriteObject(h_CorrectedYieldTree, \"hCorrectedYieldTree\" + binkey)\n",
    "            outdir_pt.WriteObject(CorrectedYieldTree, \"CorrectedYield\" + binkey)\n",
    "\n",
    "            ##### Systematic uncertainties from multi-trials, absorption effects to be added while producing the histogram#####\n",
    "            SystUnc[icent].append(h_CorrectedYieldTree.GetStdDev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce h3body yield histogram\n",
    "index_sigpdf = len(sigpdf_list) - 1\n",
    "index_bkgpdf = len(bkgpdf_list) - 1\n",
    "hStat, hSyst = data.getYieldHist(icent=0, isig=index_sigpdf, ibkg=index_bkgpdf, SystUnc=SystUnc, absorbfactor_list=AbsorbFactor,\n",
    "                                 f_corr=para.BR_3body * fRead.getEventNumber(data_type), scale_factor=para.BR_3body)\n",
    "\n",
    "# Read in the h2body yield histogram\n",
    "h2bodyStat, h2bodySyst = fRead.getH3L2bodyYieldHist(PT_BIN_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.gStyle.SetOptTitle(0)\n",
    "############### Save final results ###############\n",
    "with ROOT.TFile(output_prefix + \"Results.root\", \"recreate\") as outfile:\n",
    "    for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "        for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "            best_index = data.getBestBDTIndex(icent, ipt, index_sigpdf, index_bkgpdf)\n",
    "            print(best_index)\n",
    "            print(data.getSignalCount(icent, ipt, index_sigpdf, index_bkgpdf, best_index))\n",
    "            binkey = f\"pT{pt_bin[0]}_{pt_bin[1]}\"\n",
    "            model_threshold = score_eff_arrays_dict[binkey][0][best_index]\n",
    "            binInfo = f\"pT {pt_bin[0]}-{pt_bin[1]} GeV/c BDTEff={round(MODEL_Eff_LIST[best_index],2)}\"\n",
    "            data_se = data.getDF(icent, ipt).query(f'model_output>{model_threshold}')\n",
    "            bkg_me_deuteron = bkg_mixed_deuteron.getDF(icent, ipt).query(f'model_output>{model_threshold}')\n",
    "            bkg_me_uncorrelated = bkg_mixed_uncorrelated.getDF(icent, ipt).query(f'model_output>{model_threshold}')\n",
    "            if ipt == 0:\n",
    "                (hRawYield, canvas_bkg, canvas_signal, nsignal, err, expNBkg, bkg_peak_value) = emFit.simultaneousFit(data_se, bkg_me_deuteron, bkg_me_uncorrelated, MCFitpara[icent][ipt][0], nBins = 35, ptlims = pt_bin, lowMassLim = 2.96, highMassLim = 3.02, title = binInfo, corr_bkgPdf=bkgfunc, uncorr_bkgPdf=\"pol1\", df_column=\"fM\")\n",
    "            else:\n",
    "                (hRawYield, canvas_bkg, canvas_signal, nsignal, err, expNBkg, dummy_var) = emFit.simultaneousFit(data_se, bkg_me_deuteron, bkg_me_uncorrelated, MCFitpara[icent][ipt][0], nBins = 35, ptlims = pt_bin, lowMassLim = 2.96, highMassLim = 3.02, title = binInfo, corr_bkgPdf=bkgfunc, uncorr_bkgPdf=\"pol1\", df_column=\"fM\", corr_bkg_peak=bkg_peak_value)\n",
    "            canvas_signal.Write()\n",
    "            canvas_bkg.Write()\n",
    "            canvas_signal.SaveAs(output_prefix + \"Signal_\" + binkey + \".png\")\n",
    "            canvas_signal.SaveAs(output_prefix + \"Signal_\" + binkey + \".eps\")\n",
    "            canvas_bkg.SaveAs(output_prefix + \"Bkg_\" + binkey + \".png\")\n",
    "            canvas_bkg.SaveAs(output_prefix + \"Bkg_\" + binkey + \".eps\")\n",
    "            del hRawYield, canvas_bkg, canvas_signal\n",
    "\n",
    "        ############### Yield by assuming B.R. = 0.4 ###############\n",
    "        ROOT.gStyle.SetOptStat(0)\n",
    "        c_HypYields = utils.TCanvas('HypYields','HypYields')\n",
    "        c_HypYields.cd()\n",
    "        h_Back_Yields = ROOT.TH2F(\"h_Back_Yields\", \";#it{p}_{T} (GeV/#it{c});B.R. #times #frac{1}{N_{ev}} #frac{dN}{d#it{y}d#it{p}_{T}} (GeV/#it{c})^{-1}\", 1, 1.8, 5.2, 1, 0, max(1.*math.pow(10, -9), 1.5*hStat.GetMaximum()) )\n",
    "        # hStat.GetYaxis().SetTitle( '#frac{1}{N_{ev}} #frac{dN}{d#it{y}d#it{p}_{T}}(GeV/#it{c})^{-1}' )\n",
    "        hStat.SetMarkerColor(ROOT.kRed)\n",
    "        hStat.SetLineColor(ROOT.kRed)\n",
    "        hStat.SetMarkerStyle(8)\n",
    "        hStat.SetMarkerSize(1.5)\n",
    "        hSyst.SetFillStyle(0)\n",
    "        hSyst.SetLineColor(ROOT.kBlack)\n",
    "        hSyst.SetMarkerColor(ROOT.kBlack)\n",
    "        hSyst.SetMarkerStyle(20)\n",
    "        h_Back_Yields.Draw(\"\")\n",
    "        hStat.Draw(\"Esame\")\n",
    "        # hSyst.Draw(\"E2same\")\n",
    "\n",
    "        h2bodyStat.SetLineColor(ROOT.kBlue)\n",
    "        h2bodyStat.SetMarkerColor(ROOT.kBlue)\n",
    "        h2bodyStat.SetMarkerStyle(8)\n",
    "        h2bodyStat.SetMarkerSize(1.5)\n",
    "        h2bodyStat.Draw(\"Esame\")\n",
    "        h2bodySyst.SetFillStyle(0)\n",
    "        h2bodySyst.SetLineColor(ROOT.kBlue)\n",
    "        h2bodySyst.SetMarkerColor(ROOT.kBlue)\n",
    "        h2bodySyst.SetMarkerStyle(20)\n",
    "        # pt_spectrum.Draw(\"same\")\n",
    "        legend = ROOT.TLegend(0.6, 0.7, 0.9, 0.9)\n",
    "        # legend.AddEntry(pt_spectrum, \"2body mTExpo fit\", \"l\")\n",
    "        legend.AddEntry(hStat, \"3body yield\", \"p\")\n",
    "        legend.AddEntry(h2bodyStat, \"2body yield\", \"p\")\n",
    "        legend.Draw()\n",
    "        outfile.WriteObject(c_HypYields, 'HypYields')\n",
    "        c_HypYields.SaveAs(output_prefix + \"HypYields.png\")\n",
    "\n",
    "        ############### Ratio of B.R. ###############\n",
    "        c_R = utils.TCanvas('c_R','c_R')\n",
    "        c_R.cd()\n",
    "        h_Ratio = ROOT.TH2F(\"h_Ratio\", \";#it{p}_{T} (GeV/c);R\", 1, 1.8, 5.2, 1, 0.1, 1)\n",
    "        h_RStat = h2bodyStat.Clone(\"h_R\")\n",
    "        h_RSyst = h2bodySyst.Clone(\"h_RSyst\")\n",
    "        # Recorrect the BR of 3-body yield (2-body already corrected while readin)\n",
    "        h_SumStat = hStat.Clone(\"h_SumStat\")\n",
    "        h_SumSyst = hSyst.Clone(\"h_SumSyst\")\n",
    "        # h_SumStat.Scale(0.4)\n",
    "        # h_SumSyst.Scale(0.4)\n",
    "        # Calculate the ratio\n",
    "        h_SumStat.Add(h2bodyStat)\n",
    "        h_SumSyst.Add(h2bodySyst)\n",
    "        h_RStat.Divide(h_SumStat)\n",
    "        h_RSyst.Divide(h_SumSyst)\n",
    "        # Plot\n",
    "        h_RStat.SetTitle(\"\")\n",
    "        h_RStat.GetXaxis().SetTitle( '#it{p}_{T} (GeV/c)' )\n",
    "        h_RStat.GetYaxis().SetTitle( 'R' )\n",
    "        h_RStat.SetLineColor(ROOT.kBlue)\n",
    "        h_RStat.SetMarkerColor(ROOT.kBlue)\n",
    "        h_RStat.SetMarkerStyle(8)\n",
    "        h_RStat.SetMarkerSize(1.5)\n",
    "        h_RSyst.SetFillStyle(1)\n",
    "        h_RSyst.SetLineColor(ROOT.kBlack)\n",
    "        h_RSyst.SetMarkerColor(ROOT.kBlack)\n",
    "        h_RSyst.SetMarkerStyle(20)\n",
    "        # tf1_R = ROOT.TF1(\"tf1_R\",\"[0]\", 2, 5)\n",
    "        # h_RStat.Fit(\"tf1_R\")\n",
    "        h_Ratio.Draw(\"\")\n",
    "        h_RStat.Draw(\"Esame\")\n",
    "        # h_RSyst.Draw(\"E2same\")\n",
    "        outfile.WriteObject(c_R, 'R')\n",
    "        c_R.SaveAs(output_prefix + \"R.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
