{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from hipe4ml.model_handler import ModelHandler\n",
    "import ROOT\n",
    "ROOT.gSystem.Load('../pdfLib/libRooATan.dylib')\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.append('../include')\n",
    "import utils\n",
    "import para as para\n",
    "import fRead as fRead\n",
    "import simultaneous_fit as emFit\n",
    "from Data import dataInterval, mcDataInterval, dataGroup, mcDataGroup\n",
    "\n",
    "#ROOT.Math.IntegratorOneDimOptions.SetDefaultRelTolerance(1.E-16)\n",
    "ROOT.Math.IntegratorOneDimOptions.SetDefaultIntegrator(\"GaussLegendre\")\n",
    "#“1-dim integrators”: “Gauss”, “GaussLegendre”, “Adaptive”, “AdaptiveSingular” “NonAdaptive”\n",
    "utils.set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paramters\n",
    "CENT_BIN_LIST = para.CENT_BIN_LIST\n",
    "# PT_BIN_LIST = para.PT_BIN_LIST\n",
    "PT_BIN_LIST = para.PT_BIN_LIST_PERFORMANCE\n",
    "# PT_BIN_LIST = para.PT_BIN_LIST_NEW\n",
    "# PT_BIN_LIST = para.PT_BIN_LIST_TEST\n",
    "MASS_BIN = para.MASS_BIN\n",
    "MODEL_Eff_LIST = para.MODEL_Eff_LIST\n",
    "\n",
    "sigpdf_list = [\"dscb\"]\n",
    "# bkgpdf_list = [\"argus\", \"Landau\", \"pol5\", \"dscb\"]\n",
    "# bkgpdf_list = [\"argus\", \"pol3\", \"dscb\"]\n",
    "bkgpdf_list = [\"dscb\"]\n",
    "\n",
    "is_single_matter_type = False\n",
    "data_type = \"24skimmed\"\n",
    "# data_type = \"24skimmed_reduced\"\n",
    "# data_type = \"24skimmed_newReduced\"\n",
    "# data_type = \"24newSkimmed\"\n",
    "\n",
    "# bkgType = \"Sideband\"\n",
    "bkgType = \"LikeSign\"\n",
    "\n",
    "pt_dir = utils.convert_ptbin_to_dir(PT_BIN_LIST[0])\n",
    "if len(sigpdf_list) == 1 and len(bkgpdf_list) == 1:\n",
    "    output_prefix = f'Plot/{pt_dir}/{sigpdf_list[0]}_{bkgpdf_list[0]}/'\n",
    "else:\n",
    "    output_prefix = f\"Plot/{pt_dir}/Merged/\"\n",
    "\n",
    "if not os.path.exists(output_prefix):\n",
    "    os.makedirs(output_prefix)\n",
    "# ModelPath = \"../MLAna/Model/24skimmed\"\n",
    "# ModelPath = \"../MLAna_LikeSign/Model/24skimmed\"\n",
    "# ModelPath = \"../MLAna_LikeSign_LooseCut/Model/24skimmed\"\n",
    "# ModelPath = f\"../Model/{pt_dir}/24skimmed_{bkgType}\"\n",
    "ModelPath = f\"../ModelLooseCut/{pt_dir}/24skimmed_{bkgType}\"\n",
    "# ModelPath = f\"../Model/{pt_dir}/backup_LikeSign\"\n",
    "\n",
    "score_eff_arrays_dict = pickle.load(\n",
    "    open(ModelPath + \"/file_score_eff_dict\", \"rb\"))\n",
    "\n",
    "config_file_path = fRead.getConfigPath(data_type)\n",
    "config_file = open(config_file_path, 'r')\n",
    "config = yaml.full_load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Readin dataset and model ############### \n",
    "DataTH = fRead.getDataTH(data_type, period=\"24amanao\")\n",
    "MCTH = fRead.getMCTH(\"24skimmed_newReduced\", period=\"25a3\")\n",
    "BkgTH_mixedDeuteron = fRead.getBkgTH(\"24skimmed_newReduced\", \"mixed_deuteron\", DataTH, period=\"\")\n",
    "BkgTH_mixedUncorrelated = fRead.getBkgTH(\"24skimmed_newReduced\", \"mixed_uncorrelated\", DataTH, period=\"\")\n",
    "\n",
    "DataPDRaw = DataTH.get_data_frame()\n",
    "MCPDRaw = MCTH.get_data_frame()\n",
    "BkgPDRaw_mixed_deuteron = BkgTH_mixedDeuteron.get_data_frame()\n",
    "BkgPDRaw_mixedUncorrelated = BkgTH_mixedUncorrelated.get_data_frame()\n",
    "\n",
    "utils.calNewElements(DataPDRaw)\n",
    "utils.calNewElements(BkgPDRaw_mixed_deuteron)\n",
    "utils.calNewElements(MCPDRaw)\n",
    "utils.calNewElements(BkgPDRaw_mixedUncorrelated)\n",
    "\n",
    "DataTH.set_data_frame(DataPDRaw)\n",
    "BkgTH_mixedDeuteron.set_data_frame(BkgPDRaw_mixed_deuteron)\n",
    "BkgTH_mixedUncorrelated.set_data_frame(BkgPDRaw_mixed_deuteron)\n",
    "MCTH.set_data_frame(MCPDRaw)\n",
    "\n",
    "print(\"Count of Raw Data: \", len(DataPDRaw))\n",
    "print(\"Count of Raw MC: \", len(MCPDRaw))\n",
    "print(\"Count of Raw bkg_mixed_deuteron: \", len(BkgPDRaw_mixed_deuteron))\n",
    "print(\"Count of Raw bkg_mixed_uncorrelated: \", len(BkgPDRaw_mixedUncorrelated))\n",
    "\n",
    "if len(CENT_BIN_LIST) != 1:\n",
    "    raise ValueError(\"CENT_BIN_LIST should have only one element\") # Now we only consider one centrality bin\n",
    "\n",
    "model_hdl = utils.createEmptyList( [len(CENT_BIN_LIST)] )\n",
    "for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "    for pt_bin in PT_BIN_LIST[icent]:\n",
    "        modelfile_name = ModelPath + '/Model' + \"pT\" + str(pt_bin[0]) + \"_\" + str(pt_bin[1])\n",
    "        modelReadin = ModelHandler()\n",
    "        modelReadin.load_model_handler(modelfile_name)\n",
    "        model_hdl[icent].append(deepcopy(modelReadin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Reweight pt shape ###############\n",
    "pt_spectrum = fRead.getHypertritonPtShape(data_type)\n",
    "if PT_BIN_LIST == [[[2,5]]]:\n",
    "    utils.apply_pt_rejection(MCPDRaw, [pt_spectrum], [[-100, 999]], PT_BIN_LIST, option=\"READ\", path=\"dfResults/pTReweight_25a3_pT2_5.pkl\") # centrality unavailable\n",
    "elif PT_BIN_LIST == [[[2, 3], [3, 5]]]:\n",
    "    utils.apply_pt_rejection(MCPDRaw, [pt_spectrum], [[-100, 999]], PT_BIN_LIST, option=\"READ\", path=\"dfResults/pTReweight_25a3_pT2_3_5.pkl\")\n",
    "MCPDRaw = MCPDRaw.query(\"rej == False and fSurvivedEventSelection == True\")\n",
    "# FIXME: The raw pt distribution of mixing background is not flat! Reweight not meaningful\n",
    "# utils.apply_pt_rejection(BkgPDRaw_mixed_deuteron, [pt_spectrum], [[-100, 999]], PT_BIN_LIST, ptcolumn=\"fPt\") # centrality unavailable\n",
    "# BkgPDRaw_mixed_deuteron = BkgPDRaw_mixed_deuteron.query(\"rej == False\")\n",
    "\n",
    "print(\"After pT reweight\")\n",
    "print(\"MC dataset:\",len(MCPDRaw))\n",
    "print(\"Generated MC hypertirton within |y| < 0.5:\", len(MCPDRaw.query(\"fIsSignal == 1 and abs(fGenRapidity) < 0.5\")))\n",
    "print(\"Reconstructed MC hypertirton within 2 <= pT < 5:\", len(MCPDRaw.query(\"fIsSignal == 1 and fPt >= 2 and fPt < 5\")))\n",
    "print(\"Generated MC hypertirton within |y| < 0.5 and 2 <= pT < 3 GeV/c:\", len(MCPDRaw.query(\"fIsSignal == 1 and abs(fGenRapidity) < 0.5 and fGenPt >= 2 and fGenPt < 3\")))\n",
    "print(\"Generated MC hypertirton within |y| < 0.5 and 3 <= pT < 5 GeV/c:\", len(MCPDRaw.query(\"fIsSignal == 1 and abs(fGenRapidity) < 0.5 and fGenPt >= 3 and fGenPt < 5\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Apply precut and add model prediction to data ###############\n",
    "# print(DataPDRaw.columns)\n",
    "\n",
    "# minCosPA = 0.995\n",
    "# maxDCADaughters = 0.1\n",
    "# preCut =   f\"fCt >= 2 and fCt < 40 and \\\n",
    "#             fCosPA > {minCosPA} and \\\n",
    "#             abs(fTPCNSigmaProton) < 3 and abs(fTPCNSigmaBachelor) < 3 and \\\n",
    "#             fDCADaughters < {maxDCADaughters} and \\\n",
    "#             fDCAPionToPV > 0.05\"\n",
    "\n",
    "if \"LooseCut\" in ModelPath:\n",
    "    preCut = utils.convert_sel_to_string(config['MLLoosePreSelection'])\n",
    "else:\n",
    "    preCut = utils.convert_sel_to_string(config['MLPreSelection'])\n",
    "print(\"ML precut:\", preCut)\n",
    "\n",
    "data = dataGroup(DataPDRaw, preCut, CENT_BIN_LIST, PT_BIN_LIST, MASS_BIN, data_type, model_hdl)\n",
    "data.addModelPrediction()\n",
    "mcdata = mcDataGroup(MCPDRaw, preCut, CENT_BIN_LIST, PT_BIN_LIST, MASS_BIN, data_type + \"MC\", model_hdl) # cut for pt intervals include fPt > 0\n",
    "mcdata.addModelPrediction()\n",
    "bkg_mixed_deuteron = dataGroup(BkgPDRaw_mixed_deuteron, preCut, CENT_BIN_LIST, PT_BIN_LIST, MASS_BIN, data_type + \"Mixed_deuteron\", model_hdl)\n",
    "bkg_mixed_deuteron.addModelPrediction()\n",
    "bkg_mixed_uncorrelated = dataGroup(BkgPDRaw_mixedUncorrelated, preCut, CENT_BIN_LIST, PT_BIN_LIST, MASS_BIN, data_type + \"Mixed_uncorrelated\", model_hdl)\n",
    "bkg_mixed_uncorrelated.addModelPrediction()\n",
    "\n",
    "for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "    for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "        binCutMC = f'(fGenPt >= {pt_bin[0]}) and (fGenPt < {pt_bin[1]})'\n",
    "        print(\"gen\", len(MCPDRaw.query(f\"fIsSignal == 1 and abs(fGenRapidity) < 0.5 and {binCutMC}\")))\n",
    "        print(\"reco:\", len(mcdata.getDF(icent, ipt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Fit MC invariant mass distribution to extract the shape of signal ###############\n",
    "MCFitpara = utils.createEmptyList( [len(CENT_BIN_LIST), len(PT_BIN_LIST[0])] ) # only for DSCB\n",
    "with ROOT.TFile(output_prefix + \"MCfit.root\", \"recreate\") as outfile:\n",
    "    for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "        for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "            (_, __, paras) = mcdata.invMFit(icent, ipt, \"DSCB\", bkgpdf=\"none\", isMC=True, ifDrawStats=False, outfile = outfile)\n",
    "            MCFitpara[icent][ipt].append(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Fit data ###############\n",
    "outfileName = \"MLsimultaneousfit.root\"\n",
    "with ROOT.TFile(output_prefix + outfileName, \"recreate\") as outfile:\n",
    "    (signalCount, signalError, expBkgCount) = data.doSimultaneousFits(bkg_mixed_deuteron, bkg_mixed_uncorrelated, sigpdf_list, bkgpdf_list, \n",
    "                                                                      MODEL_Eff_LIST, score_eff_arrays_dict, mcpara_list=MCFitpara, fit_massbin=[2.96, 3.02], outfile=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Absorption factor\n",
    "# AbsorbFactor = fRead.getAbsorpFactor(CENT_BIN_LIST, PT_BIN_LIST, absorp_file = \"../CC_file/absorption_histos_3b.root\")\n",
    "AbsorbFactor = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] # To be implemented\n",
    "\n",
    "############### Calculate efficiency and expected significance ###############\n",
    "Efficiency = utils.createEmptyList( [len(CENT_BIN_LIST)] )\n",
    "ExpSignificance = utils.createEmptyList( [len(CENT_BIN_LIST), len(PT_BIN_LIST[0]), len(sigpdf_list), len(bkgpdf_list)] )\n",
    "\n",
    "with ROOT.TFile(output_prefix + \"MLsimultaneousfit.root\", \"update\") as outfile:\n",
    "    mcdata.calculateEfficiency(MCPDRaw, pt_spectrum, fRead.getEventNumber(data_type), para.BR_3body)\n",
    "    mcdata.saveEfficiencyPlots(outfile)\n",
    "    for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "        for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "            exp_signal_afterprecut = mcdata.data[icent][ipt].ExpCorrectedSignal\n",
    "            Efficiency[icent].append(mcdata.data[icent][ipt].Efficiency)\n",
    "            for isig, sigfunc in enumerate(sigpdf_list):\n",
    "                for ibkg, bkgfunc in enumerate(bkgpdf_list):\n",
    "                    for imodel, modelEff in enumerate(MODEL_Eff_LIST):\n",
    "                        ExpSignificance[icent][ipt][isig][ibkg].append(exp_signal_afterprecut * modelEff / math.sqrt(exp_signal_afterprecut + expBkgCount[icent][ipt][isig][ibkg][imodel]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### QA and systematical uncertainties ###############\n",
    "# FIXME: make code clearer\n",
    "ModelIndex = utils.createEmptyList( [len(CENT_BIN_LIST), len(PT_BIN_LIST[0]), len(sigpdf_list)] )\n",
    "SystUnc = utils.createEmptyList( [len(CENT_BIN_LIST)] )\n",
    "with ROOT.TFile(output_prefix + \"MLsimultaneousfit.root\", \"update\") as outfile:\n",
    "    for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "        SystUnc.append([])\n",
    "        outdir_cent = outfile.Get(\"Cent\"+str(cent_bin[0]) + \"_\" + str(cent_bin[1]))\n",
    "        for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "            #BDT efficiency versus output of model\n",
    "            outdir_pt = outdir_cent.Get(\"pT\"+str(pt_bin[0]) + \"_\" + str(pt_bin[1]))\n",
    "            #binkey = \"Cent\" + str(cent_bin[0]) + \"_\" + str(cent_bin[1]) + \"pT\" + str(pt_bin[0]) + \"_\" + str(pt_bin[1])\n",
    "            binkey = \"pT\" + str(pt_bin[0]) + \"_\" + str(pt_bin[1])\n",
    "            modelOutput_x = score_eff_arrays_dict[binkey][0][0:len(MODEL_Eff_LIST)]\n",
    "            BDTefficiency_y = score_eff_arrays_dict[binkey][1][0:len(MODEL_Eff_LIST)]\n",
    "            if len(MODEL_Eff_LIST) > len(BDTefficiency_y):\n",
    "                BDTefficiency_y = np.append(BDTefficiency_y, 1)\n",
    "            binInfo = \"pT\" + str(pt_bin[0]) + \"-\" + str(pt_bin[1]) + \" GeV/c\"\n",
    "            c_BDTefficiency = utils.TCanvas()\n",
    "            c_BDTefficiency.cd()\n",
    "            h_Back_BDTeff = ROOT.TH2F(\"h_Back_BDTeff\"+binInfo, binInfo + \";Model_cut;BDTefficiency\", 1,-10,15, 1,0,1.1*np.max(BDTefficiency_y) )\n",
    "            gr_BDTefficiency = ROOT.TGraph(len(MODEL_Eff_LIST), modelOutput_x, BDTefficiency_y)\n",
    "            h_Back_BDTeff.Draw()\n",
    "            gr_BDTefficiency.SetLineColor(4)\n",
    "            gr_BDTefficiency.Draw(\"LP same\")\n",
    "            outdir_pt.WriteObject(c_BDTefficiency, \"BDTefficiency\"+binkey)\n",
    "            CorrectedSignal = [] #list of corrected signal to calculate systematic uncertainties\n",
    "            for isig, sigfunc in enumerate(sigpdf_list):\n",
    "                for ibkg, bkgfunc in enumerate(bkgpdf_list):\n",
    "                    binInfo = \"pT\" + str(pt_bin[0]) + \"-\" + str(pt_bin[1]) + \" GeV/c\" + \" \" + sigfunc + \" \" + bkgfunc\n",
    "                    significance = np.array(ExpSignificance[icent][ipt][isig][ibkg])\n",
    "                    significanceMulBDTEff = significance * BDTefficiency_y\n",
    "                    c_ModelSelection = utils.TCanvas()\n",
    "                    c_ModelSelection.cd()\n",
    "                    h_Back_modelsel = ROOT.TH2F(\"h_Back_modelsel\" + binkey + sigfunc + bkgfunc, binInfo + \";Model_cut;Expected Significance #times BDT Efficiency\", 1,-10,15, 1,0,1.1*np.max(significanceMulBDTEff) )\n",
    "                    gr_ModelSelection = ROOT.TGraph(len(modelOutput_x), modelOutput_x, significanceMulBDTEff)\n",
    "                    h_Back_modelsel.Draw()\n",
    "                    gr_ModelSelection.SetLineColor(ROOT.kBlue)\n",
    "                    gr_ModelSelection.Draw(\"L same\")\n",
    "                    outdir_pt.WriteObject(c_ModelSelection, \"ModelSelection\" + binkey + sigfunc + bkgfunc)\n",
    "                    \n",
    "                    # Use the BDT threshold with the highest (significance * BDT efficiency) as the central value\n",
    "                    maxindex=np.argmax(significanceMulBDTEff)\n",
    "                    ModelIndex[icent][ipt][isig].append(maxindex)\n",
    "                    # Corrected signal counts to BDT efficiency\n",
    "                    c_SigToBDTefficiency = utils.TCanvas()\n",
    "                    c_SigToBDTefficiency.cd()\n",
    "                    SigToBDTefficiency_y = np.array(signalCount[icent][ipt][isig][ibkg])/BDTefficiency_y\n",
    "                    SigToBDTefficiency_errory = np.array(signalError[icent][ipt][isig][ibkg])/BDTefficiency_y\n",
    "                    gr_SigToBDTefficiency = ROOT.TGraphErrors(len(MODEL_Eff_LIST), np.array(MODEL_Eff_LIST), SigToBDTefficiency_y, np.zeros(len(MODEL_Eff_LIST)), SigToBDTefficiency_errory )\n",
    "                    gr_SigToBDTefficiency1 = ROOT.TGraphErrors(len(MODEL_Eff_LIST), np.array(MODEL_Eff_LIST), SigToBDTefficiency_y)\n",
    "                    tf1_sigtoBDTeff = ROOT.TF1(\"tf1_sigtoBDTeff\",\"[0]\",max(MODEL_Eff_LIST[0],0.01*maxindex),min(0.01*maxindex+0.2,MODEL_Eff_LIST[-1]))\n",
    "                    tf1_sigtoBDTeff.SetParName(0,\"mean\")\n",
    "                    tf1_sigtoBDTeff.SetLineColor(ROOT.kRed)\n",
    "                    tf1_sigtoBDTeff.SetLineStyle(2)\n",
    "                    tf1_sigtoBDTeff.SetLineWidth(2)\n",
    "                    gr_SigToBDTefficiency.SetTitle(binInfo + ';Eff_{BDT};N_{Sig} / Eff_{BDT}')\n",
    "                    gr_SigToBDTefficiency.SetFillColor(ROOT.kCyan-10)\n",
    "                    gr_SigToBDTefficiency.Draw(\"3A\")\n",
    "                    gr_SigToBDTefficiency1.SetLineColor(4)\n",
    "                    gr_SigToBDTefficiency1.SetMarkerStyle(8)\n",
    "                    gr_SigToBDTefficiency1.SetMarkerSize(0.4)\n",
    "                    # gr_SigToBDTefficiency1.Fit(\"tf1_sigtoBDTeff\",\"R\")\n",
    "                    gr_SigToBDTefficiency1.Draw(\"same LP\")\n",
    "                    outdir_pt.WriteObject(c_SigToBDTefficiency, \"SigToBDTefficiency\" + binkey + sigfunc + bkgfunc)\n",
    "                    \n",
    "                    # Vary BDT efficiency to calculate systematic uncertainties\n",
    "                    for var in range(-10, 11):\n",
    "                        if (maxindex + var >= len(MODEL_Eff_LIST)) or (maxindex + var < 0):\n",
    "                            continue\n",
    "                        CorrectedSignal.append( SigToBDTefficiency_y[maxindex+var]/(Efficiency[icent][ipt] * AbsorbFactor[icent][ipt]) )\n",
    "            # Calculate systematic uncertainties\n",
    "            binInfo = \"pT\" + str(pt_bin[0]) + \"-\" + str(pt_bin[1]) + \" GeV/c\"     \n",
    "            # Use the last case of sig and bkg_mixed_deuteron func as central value to calculate the uncertainty (now we only use the rms)\n",
    "            isig = len(sigpdf_list) - 1\n",
    "            ibkg = len(bkgpdf_list) - 1\n",
    "            \n",
    "            CorrectedYield_y = np.array(CorrectedSignal)/(fRead.getEventNumber(data_type) * para.BR_3body * 2 * (pt_bin[1] - pt_bin[0]))\n",
    "            if is_single_matter_type:\n",
    "                CorrectedYield_y = CorrectedYield_y / 2\n",
    "            h_CorrectedYield = ROOT.TH1F(\"hCorrectedYield\" + binkey, binInfo + \";Corrected Hypertriton yield;Counts\", 20, 0.8*np.min(CorrectedYield_y), 1.2*np.max(CorrectedYield_y) )\n",
    "            for sigVar in CorrectedYield_y:\n",
    "                h_CorrectedYield.Fill(sigVar)\n",
    "            outdir_pt.WriteObject(h_CorrectedYield, \"hCorrectedYield\" + binkey)\n",
    "            SystUnc[icent].append(h_CorrectedYield.GetStdDev())\n",
    "            \n",
    "            # New tree to store the corrected yield with 3 sigma region to central value\n",
    "            mean = h_CorrectedYield.GetMean()\n",
    "            rms  = h_CorrectedYield.GetRMS()\n",
    "            xTTree = np.zeros(1, dtype=np.float64)\n",
    "            h_CorrectedYieldTree = ROOT.TH1F(\"hCorrectedYieldTree\" + binkey, binInfo + \";Corrected Hypertriton yield;Counts\", 20, 0.8*np.min(CorrectedYield_y), 1.2*np.max(CorrectedYield_y) )\n",
    "            CorrectedYieldTree = ROOT.TTree(\"CorrectedYield\"+binkey, \"CorrectedYield Tree\")\n",
    "            CorrectedYieldTree.Branch(\"CorrectedYield\",xTTree,'CorrectedYield/D')\n",
    "            for sigVar in CorrectedYield_y:\n",
    "                if abs(sigVar - mean) <= 3 * rms:\n",
    "                    xTTree[0] = sigVar\n",
    "                    h_CorrectedYieldTree.Fill(sigVar)\n",
    "                    CorrectedYieldTree.Fill()\n",
    "            outdir_pt.WriteObject(h_CorrectedYieldTree, \"hCorrectedYieldTree\" + binkey)\n",
    "            outdir_pt.WriteObject(CorrectedYieldTree, \"CorrectedYield\" + binkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Calculate Yield ###############\n",
    "pt_y =[]\n",
    "for ipt, pt_bin in enumerate(PT_BIN_LIST[0]):\n",
    "    pt_y.append(pt_bin[0])\n",
    "pt_y.append(PT_BIN_LIST[0][-1][1])\n",
    "hStat = ROOT.TH1F(\"hStat\", \";#it{p}_{T} (GeV/c);R\", len(pt_y) - 1, np.array(pt_y, dtype=np.float32))\n",
    "hSyst = ROOT.TH1F(\"hSyst\", \";#it{p}_{T} (GeV/c);R\", len(pt_y) - 1, np.array(pt_y, dtype=np.float32))\n",
    "# Use the last case of sig and bkg_mixed_deuteron func as central value\n",
    "isig = len(sigpdf_list) - 1\n",
    "ibkg = len(bkgpdf_list) - 1\n",
    "for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "    print(\"Cent \" + str(cent_bin[0]) + \"-\" + str(cent_bin[1]) + \"%\")\n",
    "    for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "        binkey = \"pT\" + str(pt_bin[0]) + \"_\" + str(pt_bin[1])\n",
    "        BDTefficiency = score_eff_arrays_dict[binkey][1][0:len(MODEL_Eff_LIST)]\n",
    "        maxindex = ModelIndex[icent][ipt][isig][ibkg]\n",
    "        if len(MODEL_Eff_LIST) > len(BDTefficiency_y):\n",
    "                BDTefficiency = np.append(BDTefficiency, 1)\n",
    "        print(round(MODEL_Eff_LIST[maxindex],2), score_eff_arrays_dict[binkey][0][maxindex])\n",
    "        \n",
    "        corrfactor = para.BR_3body * fRead.getEventNumber(data_type) * Efficiency[icent][ipt] * BDTefficiency[maxindex] * AbsorbFactor[icent][ipt] * (pt_bin[1] - pt_bin[0])\n",
    "        if not is_single_matter_type:\n",
    "            corrfactor = corrfactor * 2\n",
    "        hypyield  = signalCount[icent][ipt][isig][ibkg][maxindex] / corrfactor\n",
    "        hypyield_error = signalError[icent][ipt][isig][ibkg][maxindex] / corrfactor\n",
    "\n",
    "        hStat.SetBinContent(ipt+1, hypyield)\n",
    "        hStat.SetBinError(ipt+1, hypyield_error)\n",
    "        hSyst.SetBinContent(ipt+1, hypyield)\n",
    "        hSyst.SetBinError(ipt+1, math.sqrt( math.pow( SystUnc[icent][ipt], 2) + math.pow( hypyield * (1 - AbsorbFactor[icent][ipt]) * 0.5, 2) ) )\n",
    "\n",
    "hStat.Scale(para.BR_3body)\n",
    "hSyst.Scale(para.BR_3body)\n",
    "\n",
    "# Read in the h2body histogram\n",
    "h2bodyStat, h2bodySyst = fRead.getH3L2bodyYieldHist(PT_BIN_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.gStyle.SetOptTitle(0)\n",
    "############### Save final results ###############\n",
    "with ROOT.TFile(output_prefix + \"Results.root\", \"recreate\") as outfile:\n",
    "    for icent, cent_bin in enumerate(CENT_BIN_LIST):\n",
    "        for ipt, pt_bin in enumerate(PT_BIN_LIST[icent]):\n",
    "            maxindex = ModelIndex[icent][ipt][isig][ibkg]\n",
    "            print(maxindex)\n",
    "            print(signalCount[icent][ipt][isig][ibkg][maxindex])\n",
    "            binkey =  \"pT\" + str(pt_bin[0]) + \"_\" + str(pt_bin[1])\n",
    "            model_threshold = score_eff_arrays_dict[binkey][0][maxindex]\n",
    "            binInfo = \" pT \" + str(pt_bin[0]) + \"-\" + str(pt_bin[1]) + \"GeV/c \" + \" BDTEff=\" +str(round(MODEL_Eff_LIST[maxindex],2)) #+ \" \" + data_type + \" \"\n",
    "            data_se = data.getDF(icent, ipt).query(f'model_output>{model_threshold}')\n",
    "            bkg_me_deuteron = bkg_mixed_deuteron.getDF(icent, ipt).query(f'model_output>{model_threshold}')\n",
    "            bkg_me_uncorrelated = bkg_mixed_uncorrelated.getDF(icent, ipt).query(f'model_output>{model_threshold}')\n",
    "            if ipt == 0:\n",
    "                (hRawYield, canvas_bkg, canvas_signal, nsignal, err, expNBkg, bkg_peak_value) = emFit.simultaneousFit(data_se, bkg_me_deuteron, bkg_me_uncorrelated, MCFitpara[icent][ipt][0], nBins = 35, ptlims = pt_bin, lowMassLim = 2.96, highMassLim = 3.02, title = binInfo, corr_bkgPdf=bkgfunc, uncorr_bkgPdf=\"pol1\", df_column=\"fM\")\n",
    "            else:\n",
    "                (hRawYield, canvas_bkg, canvas_signal, nsignal, err, expNBkg, dummy_var) = emFit.simultaneousFit(data_se, bkg_me_deuteron, bkg_me_uncorrelated, MCFitpara[icent][ipt][0], nBins = 35, ptlims = pt_bin, lowMassLim = 2.96, highMassLim = 3.02, title = binInfo, corr_bkgPdf=bkgfunc, uncorr_bkgPdf=\"pol1\", df_column=\"fM\", corr_bkg_peak=bkg_peak_value)\n",
    "            canvas_signal.Write()\n",
    "            canvas_bkg.Write()\n",
    "            canvas_signal.SaveAs(output_prefix + \"Signal_\" + binkey + \".png\")\n",
    "            canvas_signal.SaveAs(output_prefix + \"Signal_\" + binkey + \".eps\")\n",
    "            canvas_bkg.SaveAs(output_prefix + \"Bkg_\" + binkey + \".png\")\n",
    "            canvas_bkg.SaveAs(output_prefix + \"Bkg_\" + binkey + \".eps\")\n",
    "            del hRawYield, canvas_bkg, canvas_signal\n",
    "\n",
    "        ############### Yield by assuming B.R. = 0.4 ###############\n",
    "        ROOT.gStyle.SetOptStat(0)\n",
    "        c_HypYields = utils.TCanvas('HypYields','HypYields')\n",
    "        c_HypYields.cd()\n",
    "        h_Back_Yields = ROOT.TH2F(\"h_Back_Yields\", \";#it{p}_{T} (GeV/#it{c});B.R. #times #frac{1}{N_{ev}} #frac{dN}{d#it{y}d#it{p}_{T}} (GeV/#it{c})^{-1}\", 1, 1.8, 5.2, 1, 0, max(1.*math.pow(10, -9), 1.5*hStat.GetMaximum()) )\n",
    "        # hStat.GetYaxis().SetTitle( '#frac{1}{N_{ev}} #frac{dN}{d#it{y}d#it{p}_{T}}(GeV/#it{c})^{-1}' )\n",
    "        hStat.SetMarkerColor(ROOT.kRed)\n",
    "        hStat.SetLineColor(ROOT.kRed)\n",
    "        hStat.SetMarkerStyle(8)\n",
    "        hStat.SetMarkerSize(1.5)\n",
    "        hSyst.SetFillStyle(0)\n",
    "        hSyst.SetLineColor(ROOT.kBlack)\n",
    "        hSyst.SetMarkerColor(ROOT.kBlack)\n",
    "        hSyst.SetMarkerStyle(20)\n",
    "        h_Back_Yields.Draw(\"\")\n",
    "        hStat.Draw(\"Esame\")\n",
    "        # hSyst.Draw(\"E2same\")\n",
    "\n",
    "        h2bodyStat.SetLineColor(ROOT.kBlue)\n",
    "        h2bodyStat.SetMarkerColor(ROOT.kBlue)\n",
    "        h2bodyStat.SetMarkerStyle(8)\n",
    "        h2bodyStat.SetMarkerSize(1.5)\n",
    "        h2bodyStat.Draw(\"Esame\")\n",
    "        h2bodySyst.SetFillStyle(0)\n",
    "        h2bodySyst.SetLineColor(ROOT.kBlue)\n",
    "        h2bodySyst.SetMarkerColor(ROOT.kBlue)\n",
    "        h2bodySyst.SetMarkerStyle(20)\n",
    "        # pt_spectrum.Draw(\"same\")\n",
    "        legend = ROOT.TLegend(0.6, 0.7, 0.9, 0.9)\n",
    "        # legend.AddEntry(pt_spectrum, \"2body mTExpo fit\", \"l\")\n",
    "        legend.AddEntry(hStat, \"3body yield\", \"p\")\n",
    "        legend.AddEntry(h2bodyStat, \"2body yield\", \"p\")\n",
    "        legend.Draw()\n",
    "        outfile.WriteObject(c_HypYields, 'HypYields')\n",
    "        c_HypYields.SaveAs(output_prefix + \"HypYields.png\")\n",
    "\n",
    "        ############### Ratio of B.R. ###############\n",
    "        c_R = utils.TCanvas('c_R','c_R')\n",
    "        c_R.cd()\n",
    "        h_Ratio = ROOT.TH2F(\"h_Ratio\", \";#it{p}_{T} (GeV/c);R\", 1, 1.8, 5.2, 1, 0.1, 1)\n",
    "        h_RStat = h2bodyStat.Clone(\"h_R\")\n",
    "        h_RSyst = h2bodySyst.Clone(\"h_RSyst\")\n",
    "        # Recorrect the BR of 3-body yield (2-body already corrected while readin)\n",
    "        h_SumStat = hStat.Clone(\"h_SumStat\")\n",
    "        h_SumSyst = hSyst.Clone(\"h_SumSyst\")\n",
    "        # h_SumStat.Scale(0.4)\n",
    "        # h_SumSyst.Scale(0.4)\n",
    "        # Calculate the ratio\n",
    "        h_SumStat.Add(h2bodyStat)\n",
    "        h_SumSyst.Add(h2bodySyst)\n",
    "        h_RStat.Divide(h_SumStat)\n",
    "        h_RSyst.Divide(h_SumSyst)\n",
    "        # Plot\n",
    "        h_RStat.SetTitle(\"\")\n",
    "        h_RStat.GetXaxis().SetTitle( '#it{p}_{T} (GeV/c)' )\n",
    "        h_RStat.GetYaxis().SetTitle( 'R' )\n",
    "        h_RStat.SetLineColor(ROOT.kBlue)\n",
    "        h_RStat.SetMarkerColor(ROOT.kBlue)\n",
    "        h_RStat.SetMarkerStyle(8)\n",
    "        h_RStat.SetMarkerSize(1.5)\n",
    "        h_RSyst.SetFillStyle(1)\n",
    "        h_RSyst.SetLineColor(ROOT.kBlack)\n",
    "        h_RSyst.SetMarkerColor(ROOT.kBlack)\n",
    "        h_RSyst.SetMarkerStyle(20)\n",
    "        # tf1_R = ROOT.TF1(\"tf1_R\",\"[0]\", 2, 5)\n",
    "        # h_RStat.Fit(\"tf1_R\")\n",
    "        h_Ratio.Draw(\"\")\n",
    "        h_RStat.Draw(\"Esame\")\n",
    "        # h_RSyst.Draw(\"E2same\")\n",
    "        outfile.WriteObject(c_R, 'R')\n",
    "        c_R.SaveAs(output_prefix + \"R.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
